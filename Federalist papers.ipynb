{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Federalist papers**\n",
    "\n",
    "Alexander Hamilton, James Madison, or John Jay?  For more than 150 years, historians argued over the authorship of the 12 essays in _The Federalist Papers_. It wasn't until 1963 that the mystery was solved by Frederick Mosteller of Harvard University and David Wallace of the University of Chicago. [Nabokov's Favorite Word Is _Mauve_ by Ben Blatt]\n",
    "\n",
    "Full text of _The Federalist Papers_ is available at http://www.gutenberg.org/ebooks/1404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to our data file (source file)\n",
    "# Error handling for not being able to open file\n",
    "try:\n",
    "    source_file_name = 'federalist_papers.txt'\n",
    "    fed_papers_file = open(source_file_name, 'r')\n",
    "except IOError:\n",
    "    # cannot open file\n",
    "    print(\"Cannot open the source file\")\n",
    "except:\n",
    "    # all of the other crap gone wrong\n",
    "    print(\"A werid error has occurred\")\n",
    "if fed_papers_file != None:\n",
    "    # We can read all text at once\n",
    "    all_text = fed_papers_file.read()\n",
    "    # print(all_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are a couple of ways we could find frequencies of the words \"while\" and \"whilst\".  \n",
    "# For now, let's convert our chunk of text into a list of words\n",
    "\n",
    "word_list = all_text.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will this work?  Are words always separated by spaces?\n",
    "# While there are better methods for dealing with text parsing (for example, nltk toolkit)\n",
    "# for now we'll take care of things in a quick and dirty way\n",
    "\n",
    "punctuation_marks = ['!','.', ',', ':', ';', '?', '-', '\\n', '(', ')', '\"']\n",
    "for pm in punctuation_marks:\n",
    "    all_text = all_text.replace(pm, ' ')\n",
    "                     \n",
    "# print(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It would be a good idea to convert everything to lower case before we do anything else\n",
    "all_text = all_text.lower()\n",
    "\n",
    "# Now let's build a list of words\n",
    "word_list = all_text.split(\" \")\n",
    "# print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The frequency of 'while' is: 39\n",
      "The frequency of 'whilst' is: 24\n"
     ]
    }
   ],
   "source": [
    "# Now, let's find the frequency for \"while\"\n",
    "\n",
    "freq_while = 0\n",
    "freq_whilst = 0\n",
    "for word in word_list:\n",
    "    if word == \"while\":\n",
    "        freq_while = freq_while + 1\n",
    "    if word == \"whilst\":\n",
    "        freq_whilst = freq_whilst + 1\n",
    "        \n",
    "print(\"The frequency of 'while' is: \" + str(freq_while))\n",
    "print(\"The frequency of 'whilst' is: \" + str(freq_whilst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Why do we care about word frequencies?  Can you give me a use case with EMR data where this would be useful?\n",
    "**Answer**: In case a patient has heart stroke problems, we would like to check his/her history how many times it had occurred in the past so we could decide whether it is a genetical issue or a first time, and act differently accordingly.\n",
    "We could also check specific medications that may cause a heart stroke and see how many times the patient was prescribed with the medication.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter keyword to search word frequency: which\n"
     ]
    }
   ],
   "source": [
    "# Asks user for input\n",
    "# Error handling in case user inputs interrupt key  (Control c or delete)\n",
    "try:\n",
    "    keyword = input('Enter keyword to search word frequency: ')\n",
    "except KeyboardInterrupt:\n",
    "    print('You cancelled the operation.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert a list to dictionary( key - value ) type\n",
    "def list_to_dict(data_list): \n",
    "    data_dict = {} # create a blank dictionary\n",
    "    \n",
    "    \n",
    "    for item in data_list: # iterate through the list (passed as a parameter)\n",
    "        if item in data_dict.keys(): \n",
    "            val = data_dict[item] + 1\n",
    "            data_dict[item] = val\n",
    "        else: \n",
    "            val = 1\n",
    "            data_dict[item] = val # add key/value pair to dictionary\n",
    "       \n",
    "    return data_dict # return the resulting dictionary outside the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opens given stop words text file and save it into a list\n",
    "# Error handling for I/O file needed\n",
    "# Read the stop words from the provided text file and store them in a Python list programmatically\n",
    "def read_stop_words(file):\n",
    "    data = None \n",
    "    try:\n",
    "        # best case scenario\n",
    "        f = open(file, \"r\")\n",
    "        data = f.readlines()\n",
    "    except IOError:\n",
    "        # cannot open file\n",
    "        print(\"Cannot open the source file\")\n",
    "    except:\n",
    "        # all of the other crap gone wrong\n",
    "        print(\"A werid error has occurred\")\n",
    "    return data\n",
    "    \n",
    "# print(data)\n",
    "# print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create list to store stop words\n",
    "# Remove stop words from the body of the federalist papers (the program sometimes doesn't remove completely, so I looped it 3 times. It takes a lot of time to load but it is correct)\n",
    "# EOF exception handling happens when we are trying to delete an data that doesn't exist\n",
    "stopwords = []\n",
    "data = read_stop_words(\"common-english-words.txt\")\n",
    "\n",
    "\n",
    "for item in data: # iterate through the list (passed as a parameter)\n",
    "    stopwords = item.split(\",\") # split each item into     \n",
    "    # print(stopwords)\n",
    "try:\n",
    "    for i in range(5): # we check for stop words five times, because sometimes it doesnt remove the stop word completely\n",
    "        for word in word_list: # we iterate through the federalist paper to remove the stop words\n",
    "            if word in stopwords:\n",
    "                word_list.remove(word)        \n",
    "except EOFError:\n",
    "    print(\"Item could not be deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a key for each word appeared in the paper and value as the word frequency\n",
    "converted_data = list_to_dict(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No words are found in the federalist paper\n"
     ]
    }
   ],
   "source": [
    "# Show result of output, the keyword user entered\n",
    "try:\n",
    "    print(\"The word \" + keyword + \" appears in The Federalist Papers \" + str(converted_data[keyword])  + \" times.\")\n",
    "except:\n",
    "    print(\"No words are found in the federalist paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
